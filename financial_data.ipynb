{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de données financières : Détection d'anomalies dans un porteuille d'actifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "# instruction pour plotter dans notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# connection à quandl via l'api key\n",
    "# quandl.ApiConfig.api_key = \" 3CipYF1Y3fzjvDgg7E2n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture des données\n",
    "# df = pd.read_csv(\"all_stocks_5yr.csv\", index_col= [0,2],usecols=[0,4,6],parse_dates=[0])\n",
    "df = pd.read_csv(\"all_stocks_5yr.csv\",usecols=[0,4,6], parse_dates=[0])\n",
    "df.head()\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df = df.loc[(df.Date<datetime.datetime(2017, 8, 11,0,0,0)),:]\n",
    "df = df.loc[df.Date>datetime.datetime(2015, 8, 11,0,0,0),:]\n",
    "#df =df.dropna(axis=0, how='all').dropna(axis=1, how='any').dropna(axis=0, how='any')\n",
    "#df.loc[df.Name=='MMM',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df sans index devient un df avec index\n",
    "# df_mi = df.set_index(['Name','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On récupère les donnée sur deux ans, les données principales sont des données sur cinq ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on unstack le multi index pour en faire un \n",
    "# df_unstack = df_mi.unstack(level=0)\n",
    "#df_unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction de calcul de rendement\n",
    "# def rends(dff):\n",
    "#    return dff/dff.diff(1) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rendements journaliers obtenue à partit d'un tableau dynamique\n",
    "df_rendements = df.pivot('Date', 'Name', 'Close').pct_change() #.reset_index(level=[0]).set_index(['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fontion de calcul de moyenne mobile sur le rendement\n",
    "def rends_moov(dff):\n",
    "    return dff.rolling(window =40).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the moving average sur les rendements\n",
    "df_moving_rendements = df_rendements.apply(rends_moov)\n",
    "df_moving_rendements.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatilités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction de calcul des volatilités sur une période\n",
    "def volts(dff):\n",
    "    return dff.rolling(40).std() * np.sqrt(40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the minumum of periods to consider \n",
    "# min_periods = 75\n",
    "df_moving_volts = df_rendements.apply(volts)\n",
    "df_moving_volts.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection d'anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection sur les rendements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_2 est de dataframe qui contient les données dont on doit détecter les anomalies\n",
    "# Applications de l'isolation forest sur les données de rendements ou de volatilités\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto')\n",
    "\n",
    "# fit de l'estimateur\n",
    "clf.fit(df_moving_rendements.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any'))\n",
    "\n",
    "# the anomaly score of the input samples. the lower the more abnormal.\n",
    "scores_pred = pd.DataFrame(clf.decision_function(df_moving_rendements.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any')),index=df_moving_rendements.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any').index.values)\n",
    "\n",
    "predictions = pd.DataFrame(clf.predict(df_moving_rendements.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any')), index=df_moving_rendements.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any').index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores de tous les individus\n",
    "scores_pred.plot(figsize=(24,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les anomalies prédits ou détectées par le modèle\n",
    "predictions[predictions==-1].dropna().transpose().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le score des anomalies\n",
    "scores_pred.loc[predictions[predictions==-1].dropna().transpose().columns,:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le score des anomalies\n",
    "scores_pred.loc[predictions[predictions==-1].dropna().transpose().columns,:].plot(figsize=(24,8), title='Scores des anomalies de rendements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection sur les volatilités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_2 est de dataframe qui contient les données dont on doit détecter les anomalies\n",
    "# Applications de l'isolation forest sur les données de rendements ou de volatilités\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto')\n",
    "\n",
    "# fit de l'estimateur\n",
    "clf.fit(df_moving_volts.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any'))\n",
    "\n",
    "# the anomaly score of the input samples. the lower the more abnormal.\n",
    "scores_pred2 = pd.DataFrame(clf.decision_function(df_moving_volts.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any')),index=df_moving_volts.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any').index.values)\n",
    "\n",
    "# \n",
    "predictions2 = pd.DataFrame(clf.predict(df_moving_volts.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any')), index=df_moving_volts.transpose().dropna(axis=0, how='all').dropna(axis=1, how='any').index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores de tous les individus\n",
    "scores_pred2.plot(figsize=(24,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les anomalies prédits ou détectées par le modèle\n",
    "predictions2[predictions2==-1].dropna().transpose().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le score des anomalies\n",
    "scores_pred2.loc[predictions2[predictions2==-1].dropna().transpose().columns,:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graphique des scores des anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pred2.loc[predictions2[predictions2==-1].dropna().transpose().columns,:].plot(figsize=(24,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison anomalies obetues selon le rendements vs selon la volatilité afin de comparer quelle sont détectées dans les deux cas\n",
    "predictions2[predictions2==-1].dropna().transpose().columns.sort_values()==predictions[predictions==-1].dropna().transpose().columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection sur la fonction de densité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction d'estimation des fonction de densités des rendements des actifs\n",
    "def fdensite(X):\n",
    "    X_plot = np.linspace(-5, 10, 504)[:, np.newaxis]\n",
    "    return np.exp(KernelDensity(kernel='gaussian', bandwidth=0.75).fit(X.dropna().values.reshape(-1, 1)).score_samples(X_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_densites = df_rendements.apply(fdensite)\n",
    "df_densites.to_csv('df_densite.csv')\n",
    "df_densites.A.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_2 est de dataframe qui contient les données dont on doit détecter les anomalies\n",
    "# Applications de l'isolation forest sur les données de rendements ou de volatilités\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto')\n",
    "\n",
    "# fit de l'estimateur\n",
    "clf.fit(df_densites.transpose())\n",
    "\n",
    "# the anomaly score of the input samples. the lower the more abnormal.\n",
    "scores_pred3 = pd.DataFrame(clf.decision_function(df_densites.transpose()),index=df_densites.transpose().index.values)\n",
    "\n",
    "# \n",
    "predictions3 = pd.DataFrame(clf.predict(df_densites.transpose()), index=df_densites.transpose().index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores de tous les individus\n",
    "scores_pred3.plot(figsize=(24,8), title='Scores des desités des actifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les anomalies prédites ou détectées par le modèle\n",
    "predictions3[predictions3==-1].dropna().transpose().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le score des anomalies\n",
    "scores_pred3.loc[predictions3[predictions3==-1].dropna().transpose().columns,:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le score des anomalies\n",
    "scores_pred3.loc[predictions3[predictions3==-1].dropna().transpose().columns,:].plot(figsize=(24,8), title='Scores des anomalies de rendements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nielson siegel svensson détection sur densité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = df_rendements.A.reset_index().A.sort_values().reset_index().A.to_csv('nss_data.csv')\n",
    "a= pd.read_csv(\"sols.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_2 est de dataframe qui contient les données dont on doit détecter les anomalies\n",
    "# Applications de l'isolation forest sur les données de rendements ou de volatilités\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto')\n",
    "\n",
    "# fit de l'estimateur\n",
    "clf.fit(a)\n",
    "\n",
    "# the anomaly score of the input samples. the lower the more abnormal.\n",
    "scores_pred4 = pd.DataFrame(clf.decision_function(a),index=a.index.values)\n",
    "\n",
    "# \n",
    "predictions4 = pd.DataFrame(clf.predict(a), index=a.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores de tous les individus\n",
    "scores_pred3.plot(figsize=(24,8), title='Scores des densité des actifs ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les anomalies prédites ou détectées par le modèle\n",
    "predictions4[predictions4==-1].dropna().transpose().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3[predictions3==-1].dropna().transpose().columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
